{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4be0aab",
   "metadata": {},
   "source": [
    "    ## What Happens with No Cap?\n",
    "    If we don’t set a maximum number of flips, the average payout never settles on a number—it keeps growing as we collect those super-rare, super-large wins. In trial simulations without any cap, you might occasionally see a single run where someone flips 30+ heads and walks away with millions, and that one event pushes the calculated average higher and higher, with no end in sight. No matter how many times you rerun it, the average drifts upward instead of leveling off.\n",
    "    Without a cap, you’d need to charge an infinite ticket price to break even, because the possibility of a gigantic jackpot, however unlikely, makes the long‑run average payout unbounded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80112fdc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**1. Impose a cap**  \n",
    "If the game is limited to a maximum of K consecutive heads, the average payout becomes a specific finite number. For example, from the simulations (averaged and trimmed over multiple runs) we saw:\n",
    "- Cap K = 10 → average payout ≈ $9.90  \n",
    "- Cap K =20 → average payout ≈ $16.75  \n",
    "- Cap K =30 → average payout ≈ $17.47  \n",
    "Based on these, we’d set the ticket price to roughly $10, $17, or $17 respectively, to break even. Charging any more creates a comfortable house edge\n",
    "\n",
    "**2. Use a median or percentile price**  \n",
    "Instead of the mean, we can price by the median outcome —-- meaning exactly half of players win at least that amount. The data shows:\n",
    "- With no cap, 50% bust immediately (payout $0), so the median is $0.  \n",
    "- With K = 10, about half end by the second flip, so median payout is $2.  \n",
    "To guarantee a 75% chance the house doesn’t lose more than ticket price, we look at the 75th percentile (for K = 10 that’s around $4).\n",
    "\n",
    "**3. Use “how much fun” instead of raw dollars**\n",
    "\t•\tImagine each extra dollar you win is a little less thrilling than the one before. \n",
    "\t•\tYou ask, “What price would feel just as good as the average fun you’d get from playing?”\n",
    "\t•\tWhen you do that, the really huge but super-rare jackpots barely move the needle on “fun.”\n",
    "\t\t•\tChoose a “fun score” for each dollar win\n",
    "            Say the enjoyment of winning $X is Root X, so big jackpots (e.g.\\ $10,000) only score Root 10,000 = 100 fun points, not ten thousand.\n",
    "\t    •\tAverage those fun scores over many plays\n",
    "            Run the simulator, record ROOT payout for each outcome, and compute the mean fun score (about 3 in the experiments).\n",
    "\t    •\tConvert back to a ticket price by “unsquaring”\n",
    "            Solve Root P = 3, giving P = 3^2 = 9.  That $9 ticket delivers the same average fun as playing the uncapped game.\n",
    "\n",
    "**4. Pretend there’s a top prize limit**\n",
    "\t•\tNo casino really writes a blank check—there’s always a biggest possible payout.\n",
    "\t•\tSay you cap all winnings at $1 million, no matter how many heads you flip.\n",
    "\t•\tNow, when you average all possible wins (with that $1 million ceiling), you get a finite number—about $25 in our simulation.\n",
    "\t•\tSo you’d charge $25 per ticket, knowing you’ll never owe more than that million-dollar top prize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a23a23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "  Cap=  5 → Mean payout ≈ 4.9866\n",
    "  Cap= 10 → Mean payout ≈ 9.9030\n",
    "  Cap= 15 → Mean payout ≈ 14.8158\n",
    "  Cap= 20 → Mean payout ≈ 16.7475\n",
    "  Cap= 25 → Mean payout ≈ 19.9379\n",
    "  Cap= 30 → Mean payout ≈ 17.4718\n",
    "  Cap= 35 → Mean payout ≈ 17.1873\n",
    "  Cap= 40 → Mean payout ≈ 16.5721\n",
    "  Cap= 45 → Mean payout ≈ 28.1694\n",
    "  Cap= 50 → Mean payout ≈ 17.6503\n",
    "  Cap= 55 → Mean payout ≈ 20.5168\n",
    "  Cap= 60 → Mean payout ≈ 17.5314\n",
    "  Cap= 65 → Mean payout ≈ 17.3472\n",
    "  Cap= 70 → Mean payout ≈ 19.4374\n",
    "  Cap= 75 → Mean payout ≈ 19.3962\n",
    "  Cap= 80 → Mean payout ≈ 16.8959\n",
    "  Cap= 85 → Mean payout ≈ 22.7895\n",
    "  Cap= 90 → Mean payout ≈ 19.7774\n",
    "  Cap= 95 → Mean payout ≈ 18.9304\n",
    "  Cap=100 → Mean payout ≈ 20.4997\n",
    "Ridge test R² = 0.3460, chosen alpha = 1.0\n",
    "Ridge intercept: 2.4851094630994908\n",
    "Ridge coefficients: [-0.00507331 -0.01014662  4.37566774 -0.27601141]\n",
    "\n",
    "MLP test R²: -0.00332420059664873\n",
    "HuberRegressor test R²: 0.2424130571319868\n",
    "RANSACRegressor test R²: 0.11864427290426538\n",
    "Ridge (log-target) R² on log-scale: 0.6208542067638144\n",
    "MLP (log-target) R² on log-scale: 0.2677668509852841\n",
    "\n",
    " K |  Mean  | PolyPred | MLPPred\n",
    "---+--------+----------+--------\n",
    "  5 |   4.99 |     9.40 |   4.99\n",
    " 10 |   9.90 |    12.33 |  13.24\n",
    " 15 |  14.82 |    13.97 |  14.81\n",
    " 20 |  16.75 |    15.11 |  16.75\n",
    " 25 |  19.94 |    15.96 |  19.83\n",
    " 30 |  17.47 |    16.63 |  17.67\n",
    " 35 |  17.19 |    17.17 |  17.10\n",
    " 40 |  16.57 |    17.63 |  16.56\n",
    " 45 |  28.17 |    18.02 |  16.50\n",
    " 50 |  17.65 |    18.35 |  17.68\n",
    " 55 |  20.52 |    18.65 |  20.27\n",
    " 60 |  17.53 |    18.90 |  17.88\n",
    " 65 |  17.35 |    19.12 |  18.18\n",
    " 70 |  19.44 |    19.32 |  18.46\n",
    " 75 |  19.40 |    19.49 |  18.73\n",
    " 80 |  16.90 |    19.65 |  18.98\n",
    " 85 |  22.79 |    19.79 |  20.08\n",
    " 90 |  19.78 |    19.91 |  21.13\n",
    " 95 |  18.93 |    20.02 |  22.36\n",
    "100 |  20.50 |    20.12 |  23.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a6c5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Smoothed Monte Carlo estimates (ground‐truth averages)\n",
    "Cap=  5 → Mean payout ≈ 4.9866   # For K=5 flips max, you’ll pay out about $5 on average\n",
    "Cap= 10 → Mean payout ≈ 9.9030   # For K=10, average payout ≈ $9.90\n",
    "Cap= 15 → Mean payout ≈ 14.8158  # K=15 → ≈ $14.82\n",
    "Cap= 20 → Mean payout ≈ 16.7475  # K=20 → ≈ $16.75\n",
    "Cap= 25 → Mean payout ≈ 19.9379  # K=25 → ≈ $19.94\n",
    "Cap= 30 → Mean payout ≈ 17.4718  # K=30 → ≈ $17.47\n",
    "Cap= 35 → Mean payout ≈ 17.1873  # K=35 → ≈ $17.19\n",
    "Cap= 40 → Mean payout ≈ 16.5721  # K=40 → ≈ $16.57\n",
    "Cap= 45 → Mean payout ≈ 28.1694  # K=45 → big spike (~$28) from rare jackpots\n",
    "Cap= 50 → Mean payout ≈ 17.6503  # K=50 → ≈ $17.65\n",
    "Cap= 55 → Mean payout ≈ 20.5168  # K=55 → ≈ $20.52\n",
    "Cap= 60 → Mean payout ≈ 17.5314  # K=60 → ≈ $17.53\n",
    "Cap= 65 → Mean payout ≈ 17.3472  # K=65 → ≈ $17.35\n",
    "Cap= 70 → Mean payout ≈ 19.4374  # K=70 → ≈ $19.44\n",
    "Cap= 75 → Mean payout ≈ 19.3962  # K=75 → ≈ $19.40\n",
    "Cap= 80 → Mean payout ≈ 16.8959  # K=80 → ≈ $16.90\n",
    "Cap= 85 → Mean payout ≈ 22.7895  # K=85 → ≈ $22.79\n",
    "Cap= 90 → Mean payout ≈ 19.7774  # K=90 → ≈ $19.78\n",
    "Cap= 95 → Mean payout ≈ 18.9304  # K=95 → ≈ $18.93\n",
    "Cap=100 → Mean payout ≈ 20.4997  # K=100 → ≈ $20.50\n",
    "\n",
    "# 2) Linear (Ridge) regression on raw payouts\n",
    "Ridge test R² = 0.3460           # Model explains ~35% of the variation\n",
    "chosen alpha = 1.0               # Regularization strength selected by CV\n",
    "Ridge intercept: 2.4851          # Base payout when all features are zero\n",
    "Ridge coefficients:              # Weights on [K, analytic, logK, tail_corr]\n",
    "[-0.00507, -0.01015, 4.37567, -0.27601]\n",
    "\n",
    "# 3) Neural net (MLP) on raw payouts\n",
    "MLP test R²: -0.0033             # Essentially no predictive power here\n",
    "\n",
    "# 4) Robust regressors to down‐weight outliers\n",
    "HuberRegressor test R²: 0.2424    # Ignores extreme spikes—fits core data (~24% explained)\n",
    "RANSACRegressor test R²: 0.1186   # Fits only the largest consistent subset (~12% explained)\n",
    "\n",
    "# 5) Ridge on log‐transformed payouts\n",
    "Ridge (log-target) R² on log-scale: 0.6209  # Compressing jackpots yields ~62% explained \n",
    "\n",
    "# 6) Neural net on log‐transformed payouts\n",
    "MLP (log-target) R² on log-scale: 0.2678  # Improves to ~27% but still below linear model\n",
    "\n",
    "# 7) Final prediction comparison (raw‐scale models)\n",
    " K |  Mean   | PolyPred | MLPPred\n",
    "---+---------+----------+---------\n",
    "  5 |   4.99  |     9.40 |    4.99  # Raw Ridge overshoots, MLP nails K=5\n",
    " 10 |   9.90  |    12.33 |   13.24  # Both models overestimate a bit \n",
    " 15 |  14.82  |    13.97 |   14.81  # Ridge slightly low, MLP nearly exact \n",
    " 20 |  16.75  |    15.11 |   16.75  # Ridge underestimates, MLP perfect \n",
    " … \n",
    " 45 |  28.17  |    18.02 |   16.50  # Wild true mean spike; both models smooth it out \n",
    " … \n",
    "100 |  20.50  |    20.12 |   23.67  # Ridge very close, MLP overshoots at high K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fcbc75",
   "metadata": {},
   "source": [
    "•\tThe Monte Carlo means are “ground truth” but still noisy at high caps.\n",
    "•\tRaw‐scale Ridge is a simple, interpretable fit explaining ~35% of variance.\n",
    "•\tLog‐scale Ridge is the best fit, capturing ~62% by taming the big-jackpot effect.\n",
    "•\tRobust methods (Huber, RANSAC) help if you want to ignore outliers but lose overall explanatory power.\n",
    "•\tNeural nets add little here—engineered features plus a linear model suffice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
