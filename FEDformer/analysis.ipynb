{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63228fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 32, dec_modes: 32\n",
      "Loading weights from: /Users/mchildress/Active Code/ts_basics/FEDformer/models/fedformer.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mchildress/Active Code/ts_basics/FEDformer/data/windows.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 5. Grab one example batch from your data\u001b[39;00m\n\u001b[1;32m     38\u001b[0m data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(proj, cfg_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m bx \u001b[38;5;241m=\u001b[39m X[:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# shape (1, seq_len, 1)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m by \u001b[38;5;241m=\u001b[39m Y[:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/dream/lib/python3.11/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/dream/lib/python3.11/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/dream/lib/python3.11/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mchildress/Active Code/ts_basics/FEDformer/data/windows.pt'"
     ]
    }
   ],
   "source": [
    "# analysis.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Ensure train.py (and its Configs) is importable\n",
    "proj = os.getcwd()  # assume notebook is opened in FEDformer/\n",
    "sys.path.insert(0, os.path.join(proj, \"scripts\"))\n",
    "\n",
    "from train import Configs, load_yaml_config\n",
    "from fedformer.models.FEDformer import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 2. Load config dict and wrap in Configs\n",
    "cfg_dict = load_yaml_config()\n",
    "configs = Configs(cfg_dict)\n",
    "\n",
    "# 3. Rebuild your scaler (use the same params you saved in preprocess)\n",
    "scaler = StandardScaler()\n",
    "# scaler.mean_ and scaler.scale_ must match what you used in preprocess:\n",
    "# e.g. scaler.mean_ = [mean_close]; scaler.scale_ = [std_close]\n",
    "\n",
    "# 4. Instantiate and load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(configs).to(device)\n",
    "\n",
    "# Confirm the exact path weâ€™re loading from\n",
    "state_dict_path = os.path.join(proj, \"models\", \"fedformer.pth\")\n",
    "print(\"Loading weights from:\", state_dict_path)\n",
    "\n",
    "model.load_state_dict(torch.load(state_dict_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 5. Grab one example batch from your data\n",
    "data_path = os.path.join(proj, cfg_dict[\"data\"][\"tensor_path\"])\n",
    "X, Y = torch.load(data_path)\n",
    "bx = X[:1].to(device)  # shape (1, seq_len, 1)\n",
    "by = Y[:1].to(device)\n",
    "\n",
    "# 6. Run inference\n",
    "with torch.no_grad():\n",
    "    # Create dummy time features as in train.py\n",
    "    zeros_enc = torch.zeros_like(bx, device=device)\n",
    "    zeros_dec = torch.zeros(1, configs.pred_len, zeros_enc.size(-1), device=device)\n",
    "    pred = model(bx, zeros_enc, by, zeros_dec)  # (1, pred_len, 1)\n",
    "\n",
    "# 7. Plot normalized predictions vs. truth\n",
    "y_true = by.cpu().numpy().squeeze()\n",
    "y_pred = pred.cpu().numpy().squeeze()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(len(y_true)), y_true, label=\"True\")\n",
    "plt.plot(range(len(y_true), len(y_true) + len(y_pred)), y_pred, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.title(\"FEDformer Forecast vs Ground Truth (normalized)\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Normalized value\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
